{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries we'll need\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_status</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>sensor_08</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_41</th>\n",
       "      <th>sensor_42</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.3750</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>15.56713</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770832</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.8889</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>15.61777</td>\n",
       "      <td>...</td>\n",
       "      <td>31.770830</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.1684</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.1250</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>240.4514</td>\n",
       "      <td>203.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.2118</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.4583</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>15.69734</td>\n",
       "      <td>...</td>\n",
       "      <td>31.510420</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>242.1875</td>\n",
       "      <td>201.3889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   machine_status  sensor_00  sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
       "0               0   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "1               0   2.465394   47.09201    53.2118  46.310760   634.3750   \n",
       "2               0   2.444734   47.35243    53.2118  46.397570   638.8889   \n",
       "3               0   2.460474   47.09201    53.1684  46.397568   628.1250   \n",
       "4               0   2.445718   47.13541    53.2118  46.397568   636.4583   \n",
       "\n",
       "   sensor_05  sensor_06  sensor_07  sensor_08  ...  sensor_41  sensor_42  \\\n",
       "0   76.45975   13.41146   16.13136   15.56713  ...  31.770832   41.92708   \n",
       "1   76.45975   13.41146   16.13136   15.56713  ...  31.770832   41.92708   \n",
       "2   73.54598   13.32465   16.03733   15.61777  ...  31.770830   41.66666   \n",
       "3   76.98898   13.31742   16.24711   15.69734  ...  31.510420   40.88541   \n",
       "4   76.58897   13.35359   16.21094   15.69734  ...  31.510420   41.40625   \n",
       "\n",
       "   sensor_43  sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  \\\n",
       "0  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "1  39.641200   65.68287   50.92593  38.194440   157.9861   67.70834   \n",
       "2  39.351852   65.39352   51.21528  38.194443   155.9606   67.12963   \n",
       "3  39.062500   64.81481   51.21528  38.194440   155.9606   66.84028   \n",
       "4  38.773150   65.10416   51.79398  38.773150   158.2755   66.55093   \n",
       "\n",
       "   sensor_49  sensor_50  \n",
       "0   243.0556   201.3889  \n",
       "1   243.0556   201.3889  \n",
       "2   241.3194   203.7037  \n",
       "3   240.4514   203.1250  \n",
       "4   242.1875   201.3889  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data\n",
    "df = pd.read_csv(r'P:\\ENGINEERING\\FPO\\Digitalisation\\1 FPO Projects\\IIX Data Analytics\\02-General presentations\\Knowledge folder - preparation\\Data Science Learning Framework\\Machine Learning Posters\\6 - Anomaly Detection\\sensor.csv')\n",
    "#there are 51 sensors for the pump, and a label (0 for operational, 1 for broken) of the machine\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating into training, cross validation and test sets\n",
    "df = df.dropna(axis=0, how=\"any\") #dropping nulls\n",
    "#training data, no positives as not needed and to save as many as possible for cross validation/ testing\n",
    "x = np.array(df[df[\"machine_status\"]==0].drop([\"machine_status\"], axis=1))\n",
    "y = np.array(df[df[\"machine_status\"]==0][\"machine_status\"])[:,np.newaxis]\n",
    "\n",
    "x_pos = np.array(df[df[\"machine_status\"]==1].drop([\"machine_status\"], axis=1)) #putting positive data into new array\n",
    "x_pos = x_pos[np.random.permutation(len(x_pos))] #shuffling array\n",
    "y_pos = np.array(df[df[\"machine_status\"]==1][\"machine_status\"])[:,np.newaxis]\n",
    "\n",
    "#creating random index to pull negative values from training set into cross validation and test sets\n",
    "random_index = np.random.randint(len(x), size=(10000))            \n",
    "\n",
    "#creating cross validation and test sets from positive and negative examples\n",
    "x_cv = np.append(x[random_index[:5000],:], x_pos[:int(len(x_pos)/2)], axis=0)\n",
    "y_cv = np.append(y[random_index[:5000],:], y_pos[int(len(y_pos)/2):], axis=0)\n",
    "x_test = np.append(x[random_index[5000:],:], x_pos[:int(len(x_pos)/2)], axis=0)\n",
    "y_test = np.append(y[random_index[5000:],:], y_pos[int(len(y_pos)/2):], axis=0)\n",
    "\n",
    "#removing cross validation and test examples from training set\n",
    "x = np.delete(x, random_index, axis=0)\n",
    "y = np.delete(y, random_index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Anomaly Detection Algorithm (as a class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomaly_detection(object):\n",
    "    def __init__(self, x):\n",
    "        '''__init__ function to define the training data and their mean as objects within the class,\n",
    "           as well as calculate the covariance matrix\n",
    "           '''\n",
    "        self.x = np.array(x)\n",
    "        self.x_mean = np.mean(self.x, axis=0)\n",
    "        def sigma_calc(self):\n",
    "            '''calculating the covariance matrix\n",
    "            '''\n",
    "            return (1/len(self.x))*np.sum(np.array([np.dot(i[:,np.newaxis]-self.x_mean,\n",
    "                                                          (i[:,np.newaxis]-self.x_mean).transpose())\n",
    "                                                          for i in self.x]),axis=0)\n",
    "\n",
    "        self.sigma = sigma_calc(self)\n",
    "\n",
    "    def p_calc(self, x, x_mean):\n",
    "        '''calculate p (Gaussian Distribution value) for all rows in the given dataset\n",
    "           (can take a while as needs to calculate inverse of large matrix)\n",
    "        '''\n",
    "        return (1/((2*np.pi)**x.shape[1]*np.linalg.det(self.sigma)**0.5))*np.e**np.array([-0.5*np.dot( \n",
    "                                                                                                 np.dot(\n",
    "                                                                                                       (i-x_mean),\n",
    "                                                                                                       np.linalg.inv(self.sigma)), \n",
    "                                                                                                       ((i-x_mean).transpose())) \n",
    "                                                                                                       for i in x])\n",
    "\n",
    "    def z_optimiser(self, p, y, x, iterations):\n",
    "        '''optimises cut-off value of z based on maximising precision and recall, ideally using the cross validation set\n",
    "        '''\n",
    "        #creating vectors to fill with precision/recall values for different values of z\n",
    "        pres_rec_vectors = np.zeros((iterations))\n",
    "        precisions = np.zeros((iterations))\n",
    "        recalls = np.zeros((iterations))\n",
    "        #iterating over z\n",
    "        for i, z in enumerate(np.linspace(min(p), max(p), iterations)):\n",
    "            #define precision, recall and the euclidian length of them (to maximise for optimum z)\n",
    "            precisions[i] = len(p[(p <= z) & (y == 1)])/(len(p[(p <= z) & (y == 1)])+len(p[(p <= z) & (y == 0)]))\n",
    "            recalls[i] = len(p[(p <= z) & (y == 1)])/(len(p[(p <= z) & (y == 1)])+len(p[(p >= z) & (y == 1)]))\n",
    "            pres_rec_vectors[i] = np.sqrt(precisions[i]**2+recalls[i]**2)\n",
    "        \n",
    "        #picking optimal z, and its precision and recall\n",
    "        z_opt = np.linspace(min(p), max(p), iterations)[np.argmax(pres_rec_vectors)]\n",
    "        pres_opt = precisions[np.argmax(pres_rec_vectors)]\n",
    "        recall_opt = recalls[np.argmax(pres_rec_vectors)]\n",
    "\n",
    "        print(\"z optimised at {}, with precision {} and recall {}\".format(z_opt, np.round(pres_opt,3), np.round(recall_opt,3)))\n",
    "\n",
    "        return z_opt\n",
    "\n",
    "    def anom_pred_calc(self, p, z):\n",
    "        '''returns a boolean vector fo whether p is bigger than z for all data rows, i.e. classifying as anomaly or not'''\n",
    "        anom_pred = (p < z).astype(int)\n",
    "        return anom_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = anomaly_detection(x) #creating anomaly detection object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Cross Validation to Optimise Z (using cross validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z optimised at 3.276566533284943e-143, with precision 0.83 and recall 0.996\n"
     ]
    }
   ],
   "source": [
    "p = ad.p_calc(x_cv, np.mean(x_cv, axis=0)) #calculating p for data in the cross validation set\n",
    "z = ad.z_optimiser(p, y_cv.flatten(), x_cv, 10000) #optimising z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ad.p_calc(x_test, np.mean(x_test, axis=0)) #calculating p for data in the test set\n",
    "anom_pred = ad.anom_pred_calc(p, z) #predicting if anomaly or not (based on p & z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({\"P\":p, \"label\":y_test[:,0], \"predicted_label\":anom_pred}) #creating dataframe of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "1476 314\n",
      "9 4686\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(len(summary_df[(summary_df[\"label\"] == 1) & (summary_df[\"predicted_label\"] == 1)]), len(summary_df[(summary_df[\"label\"] == 0) & (summary_df[\"predicted_label\"] == 1)]))\n",
    "print(len(summary_df[(summary_df[\"label\"] == 1) & (summary_df[\"predicted_label\"] == 0)]), len(summary_df[(summary_df[\"label\"] == 0) & (summary_df[\"predicted_label\"] == 0)]))\n",
    "\n",
    "#confusion matrix is of the form:\n",
    "#top left number: True positives - no. of examples in the test set that were positive (pump down) and identified as such\n",
    "#top right number: False positive - no. of examples predicted_label as postive but actually negative (pump operational)\n",
    "#bottom left number: False negative - no. of examples predicted_label as negative but actually positive\n",
    "#bottom right number: True negative - no. of examples predicted_label as negative and identified as such"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has few false negatives or positives compared to correctly classified data, and as such we can be confident it will identify when the pump has failed much more accurately than without a model. The model has many more false positives than negatives, so we may be able to improve performance by increasing z a small amount, but it's important to do this based on the cross-validation set rather than the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
